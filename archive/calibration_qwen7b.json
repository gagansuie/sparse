{
  "model": "Qwen/Qwen2-7B",
  "num_samples": 0,
  "sensitivity": {
    "model.layers.0.self_attn.q_proj": 0.7872340341783614,
    "model.layers.0.self_attn.k_proj": 0.7872340341783614,
    "model.layers.0.self_attn.v_proj": 0.5744680789950204,
    "model.layers.0.self_attn.o_proj": 0.5744680789950204,
    "model.layers.0.mlp.gate_proj": 0.36170212381167954,
    "model.layers.0.mlp.up_proj": 0.36170212381167954,
    "model.layers.0.mlp.down_proj": 0.25531914622000906,
    "model.layers.1.self_attn.q_proj": 0.7620173283788542,
    "model.layers.1.self_attn.k_proj": 0.7620173283788542,
    "model.layers.1.self_attn.v_proj": 0.5555555496453901,
    "model.layers.1.self_attn.o_proj": 0.5555555496453901,
    "model.layers.1.mlp.gate_proj": 0.34909377091192595,
    "model.layers.1.mlp.up_proj": 0.34909377091192595,
    "model.layers.1.mlp.down_proj": 0.2458628815451939,
    "model.layers.2.self_attn.q_proj": 0.7368006225793473,
    "model.layers.2.self_attn.k_proj": 0.7368006225793473,
    "model.layers.2.self_attn.v_proj": 0.5366430202957598,
    "model.layers.2.self_attn.o_proj": 0.5366430202957598,
    "model.layers.2.mlp.gate_proj": 0.33648541801217247,
    "model.layers.2.mlp.up_proj": 0.33648541801217247,
    "model.layers.2.mlp.down_proj": 0.23640661687037873,
    "model.layers.3.self_attn.q_proj": 0.7115839167798401,
    "model.layers.3.self_attn.k_proj": 0.7115839167798401,
    "model.layers.3.self_attn.v_proj": 0.5177304909461294,
    "model.layers.3.self_attn.o_proj": 0.5177304909461294,
    "model.layers.3.mlp.gate_proj": 0.3238770651124189,
    "model.layers.3.mlp.up_proj": 0.3238770651124189,
    "model.layers.3.mlp.down_proj": 0.2269503521955636,
    "model.layers.4.self_attn.q_proj": 0.6863672109803332,
    "model.layers.4.self_attn.k_proj": 0.6863672109803332,
    "model.layers.4.self_attn.v_proj": 0.49881796159649916,
    "model.layers.4.self_attn.o_proj": 0.49881796159649916,
    "model.layers.4.mlp.gate_proj": 0.3112687122126654,
    "model.layers.4.mlp.up_proj": 0.3112687122126654,
    "model.layers.4.mlp.down_proj": 0.21749408752074845,
    "model.layers.5.self_attn.q_proj": 0.6611505051808261,
    "model.layers.5.self_attn.k_proj": 0.6611505051808261,
    "model.layers.5.self_attn.v_proj": 0.4799054322468688,
    "model.layers.5.self_attn.o_proj": 0.4799054322468688,
    "model.layers.5.mlp.gate_proj": 0.2986603593129119,
    "model.layers.5.mlp.up_proj": 0.2986603593129119,
    "model.layers.5.mlp.down_proj": 0.20803782284593328,
    "model.layers.6.self_attn.q_proj": 0.6359337993813189,
    "model.layers.6.self_attn.k_proj": 0.6359337993813189,
    "model.layers.6.self_attn.v_proj": 0.46099290289723854,
    "model.layers.6.self_attn.o_proj": 0.46099290289723854,
    "model.layers.6.mlp.gate_proj": 0.2860520064131583,
    "model.layers.6.mlp.up_proj": 0.2860520064131583,
    "model.layers.6.mlp.down_proj": 0.19858155817111814,
    "model.layers.7.self_attn.q_proj": 0.6107170935818119,
    "model.layers.7.self_attn.k_proj": 0.6107170935818119,
    "model.layers.7.self_attn.v_proj": 0.44208037354760826,
    "model.layers.7.self_attn.o_proj": 0.44208037354760826,
    "model.layers.7.mlp.gate_proj": 0.27344365351340477,
    "model.layers.7.mlp.up_proj": 0.27344365351340477,
    "model.layers.7.mlp.down_proj": 0.18912529349630303,
    "model.layers.8.self_attn.q_proj": 0.5855003877823048,
    "model.layers.8.self_attn.k_proj": 0.5855003877823048,
    "model.layers.8.self_attn.v_proj": 0.4231678441979779,
    "model.layers.8.self_attn.o_proj": 0.4231678441979779,
    "model.layers.8.mlp.gate_proj": 0.2608353006136513,
    "model.layers.8.mlp.up_proj": 0.2608353006136513,
    "model.layers.8.mlp.down_proj": 0.17966902882148783,
    "model.layers.9.self_attn.q_proj": 0.5602836819827979,
    "model.layers.9.self_attn.k_proj": 0.5602836819827979,
    "model.layers.9.self_attn.v_proj": 0.40425531484834765,
    "model.layers.9.self_attn.o_proj": 0.40425531484834765,
    "model.layers.9.mlp.gate_proj": 0.24822694771389775,
    "model.layers.9.mlp.up_proj": 0.24822694771389775,
    "model.layers.9.mlp.down_proj": 0.17021276414667275,
    "model.layers.10.self_attn.q_proj": 0.5350669761832907,
    "model.layers.10.self_attn.k_proj": 0.5350669761832907,
    "model.layers.10.self_attn.v_proj": 0.38534278549871737,
    "model.layers.10.self_attn.o_proj": 0.38534278549871737,
    "model.layers.10.mlp.gate_proj": 0.23561859481414418,
    "model.layers.10.mlp.up_proj": 0.23561859481414418,
    "model.layers.10.mlp.down_proj": 0.16075649947185758,
    "model.layers.11.self_attn.q_proj": 0.5098502703837835,
    "model.layers.11.self_attn.k_proj": 0.5098502703837835,
    "model.layers.11.self_attn.v_proj": 0.3664302561490871,
    "model.layers.11.self_attn.o_proj": 0.3664302561490871,
    "model.layers.11.mlp.gate_proj": 0.22301024191439062,
    "model.layers.11.mlp.up_proj": 0.22301024191439062,
    "model.layers.11.mlp.down_proj": 0.15130023479704244,
    "model.layers.12.self_attn.q_proj": 0.4846335645842764,
    "model.layers.12.self_attn.k_proj": 0.4846335645842764,
    "model.layers.12.self_attn.v_proj": 0.3475177267994567,
    "model.layers.12.self_attn.o_proj": 0.3475177267994567,
    "model.layers.12.mlp.gate_proj": 0.21040188901463708,
    "model.layers.12.mlp.up_proj": 0.21040188901463708,
    "model.layers.12.mlp.down_proj": 0.14184397012222721,
    "model.layers.13.self_attn.q_proj": 0.4594168587847694,
    "model.layers.13.self_attn.k_proj": 0.4594168587847694,
    "model.layers.13.self_attn.v_proj": 0.32860519744982647,
    "model.layers.13.self_attn.o_proj": 0.32860519744982647,
    "model.layers.13.mlp.gate_proj": 0.19779353611488357,
    "model.layers.13.mlp.up_proj": 0.19779353611488357,
    "model.layers.13.mlp.down_proj": 0.1323877054474121,
    "model.layers.14.self_attn.q_proj": 0.4342001529852624,
    "model.layers.14.self_attn.k_proj": 0.4342001529852624,
    "model.layers.14.self_attn.v_proj": 0.3096926681001962,
    "model.layers.14.self_attn.o_proj": 0.3096926681001962,
    "model.layers.14.mlp.gate_proj": 0.18518518321513006,
    "model.layers.14.mlp.up_proj": 0.18518518321513006,
    "model.layers.14.mlp.down_proj": 0.12293144077259699,
    "model.layers.15.self_attn.q_proj": 0.4089834471857553,
    "model.layers.15.self_attn.k_proj": 0.4089834471857553,
    "model.layers.15.self_attn.v_proj": 0.29078013875056585,
    "model.layers.15.self_attn.o_proj": 0.29078013875056585,
    "model.layers.15.mlp.gate_proj": 0.17257683031537654,
    "model.layers.15.mlp.up_proj": 0.17257683031537654,
    "model.layers.15.mlp.down_proj": 0.11347517609778181,
    "model.layers.16.self_attn.q_proj": 0.38376674138624817,
    "model.layers.16.self_attn.k_proj": 0.38376674138624817,
    "model.layers.16.self_attn.v_proj": 0.2718676094009356,
    "model.layers.16.self_attn.o_proj": 0.2718676094009356,
    "model.layers.16.mlp.gate_proj": 0.15996847741562295,
    "model.layers.16.mlp.up_proj": 0.15996847741562295,
    "model.layers.16.mlp.down_proj": 0.10401891142296665,
    "model.layers.17.self_attn.q_proj": 0.3585500355867411,
    "model.layers.17.self_attn.k_proj": 0.3585500355867411,
    "model.layers.17.self_attn.v_proj": 0.25295508005130524,
    "model.layers.17.self_attn.o_proj": 0.25295508005130524,
    "model.layers.17.mlp.gate_proj": 0.14736012451586944,
    "model.layers.17.mlp.up_proj": 0.14736012451586944,
    "model.layers.17.mlp.down_proj": 0.0945626467481515,
    "model.layers.18.self_attn.q_proj": 0.33333332978723407,
    "model.layers.18.self_attn.k_proj": 0.33333332978723407,
    "model.layers.18.self_attn.v_proj": 0.23404255070167493,
    "model.layers.18.self_attn.o_proj": 0.23404255070167493,
    "model.layers.18.mlp.gate_proj": 0.13475177161611593,
    "model.layers.18.mlp.up_proj": 0.13475177161611593,
    "model.layers.18.mlp.down_proj": 0.08510638207333636,
    "model.layers.19.self_attn.q_proj": 0.308116623987727,
    "model.layers.19.self_attn.k_proj": 0.308116623987727,
    "model.layers.19.self_attn.v_proj": 0.21513002135204462,
    "model.layers.19.self_attn.o_proj": 0.21513002135204462,
    "model.layers.19.mlp.gate_proj": 0.12214341871636238,
    "model.layers.19.mlp.up_proj": 0.12214341871636238,
    "model.layers.19.mlp.down_proj": 0.0756501173985212,
    "model.layers.20.self_attn.q_proj": 0.2828999181882199,
    "model.layers.20.self_attn.k_proj": 0.2828999181882199,
    "model.layers.20.self_attn.v_proj": 0.1962174920024144,
    "model.layers.20.self_attn.o_proj": 0.1962174920024144,
    "model.layers.20.mlp.gate_proj": 0.10953506581660885,
    "model.layers.20.mlp.up_proj": 0.10953506581660885,
    "model.layers.20.mlp.down_proj": 0.06619385272370608,
    "model.layers.21.self_attn.q_proj": 0.25768321238871283,
    "model.layers.21.self_attn.k_proj": 0.25768321238871283,
    "model.layers.21.self_attn.v_proj": 0.1773049626527841,
    "model.layers.21.self_attn.o_proj": 0.1773049626527841,
    "model.layers.21.mlp.gate_proj": 0.09692671291685531,
    "model.layers.21.mlp.up_proj": 0.09692671291685531,
    "model.layers.21.mlp.down_proj": 0.05673758804889091,
    "model.layers.22.self_attn.q_proj": 0.23246650658920576,
    "model.layers.22.self_attn.k_proj": 0.23246650658920576,
    "model.layers.22.self_attn.v_proj": 0.15839243330315372,
    "model.layers.22.self_attn.o_proj": 0.15839243330315372,
    "model.layers.22.mlp.gate_proj": 0.08431836001710176,
    "model.layers.22.mlp.up_proj": 0.08431836001710176,
    "model.layers.22.mlp.down_proj": 0.04728132337407574,
    "model.layers.23.self_attn.q_proj": 0.20724980078969865,
    "model.layers.23.self_attn.k_proj": 0.20724980078969865,
    "model.layers.23.self_attn.v_proj": 0.13947990395352342,
    "model.layers.23.self_attn.o_proj": 0.13947990395352342,
    "model.layers.23.mlp.gate_proj": 0.07171000711734822,
    "model.layers.23.mlp.up_proj": 0.07171000711734822,
    "model.layers.23.mlp.down_proj": 0.03782505869926058,
    "model.layers.24.self_attn.q_proj": 0.18203309499019163,
    "model.layers.24.self_attn.k_proj": 0.18203309499019163,
    "model.layers.24.self_attn.v_proj": 0.12056737460389316,
    "model.layers.24.self_attn.o_proj": 0.12056737460389316,
    "model.layers.24.mlp.gate_proj": 0.0591016542175947,
    "model.layers.24.mlp.up_proj": 0.0591016542175947,
    "model.layers.24.mlp.down_proj": 0.028368794024445455,
    "model.layers.25.self_attn.q_proj": 0.15681638919068455,
    "model.layers.25.self_attn.k_proj": 0.15681638919068455,
    "model.layers.25.self_attn.v_proj": 0.10165484525426283,
    "model.layers.25.self_attn.o_proj": 0.10165484525426283,
    "model.layers.25.mlp.gate_proj": 0.04649330131784116,
    "model.layers.25.mlp.up_proj": 0.04649330131784116,
    "model.layers.25.mlp.down_proj": 0.01891252934963029,
    "model.layers.26.self_attn.q_proj": 0.13159968339117753,
    "model.layers.26.self_attn.k_proj": 0.13159968339117753,
    "model.layers.26.self_attn.v_proj": 0.08274231590463257,
    "model.layers.26.self_attn.o_proj": 0.08274231590463257,
    "model.layers.26.mlp.gate_proj": 0.03388494841808764,
    "model.layers.26.mlp.up_proj": 0.03388494841808764,
    "model.layers.26.mlp.down_proj": 0.009456264674815166,
    "model.layers.27.self_attn.q_proj": 0.10638297759167042,
    "model.layers.27.self_attn.k_proj": 0.10638297759167042,
    "model.layers.27.self_attn.v_proj": 0.06382978655500225,
    "model.layers.27.self_attn.o_proj": 0.06382978655500225,
    "model.layers.27.mlp.gate_proj": 0.021276595518334093,
    "model.layers.27.mlp.up_proj": 0.021276595518334093,
    "model.layers.27.mlp.down_proj": 0.0,
    "lm_head": 0.9999999893617022
  },
  "activation_scales": {}
}